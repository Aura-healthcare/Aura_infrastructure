input {
   file {
	# chemin vers les fichiers sur notre Host
	path => ["{{logstash_data_container_location}}/*_RrInterval_*"]
	type => "RrInterval"
	codec => "json"
	# Logstash commence par lire les fichiers qui sont au début
	start_position => "beginning"
    ignore_older => 0
    #sincedb_path => "/home/logstash/data/since_db_filed"
   }
}

filter{

	json {
		source => "message"
		# Option pour ignorer le parsing et l'envoi de donnée
		# si le format json n'est pas respectée
		#skip_on_invalid_json => true
	}

	# Splitter le champ data ["time1 value1", "time2 value2", etc ...]
	# pour rentrer chaque ligne avec la même vaeur user, device_address
	split { field => "data"}

	# Spliter le contenu du champ data en 2 valeurs : timestamp et value
	mutate {
		split => {"data" => " "}
		add_field => {"time_bis" => "%{data[0]}"}
		add_field => {"value" => "%{data[1]}"}
	}

	# Decoder le timestamp et remplacer le @timestamp généré par Logstash par cette valeur
        date {
        	timezone => "UTC"
        	match => ["time_bis", "ISO8601"]
        	target => "@timestamp"
	}

}

output {
   stdout {}
   if [type] == "RrInterval" {
      influxdb {

        id => "RrInterval"

      	# allow_time_override => true
      	# Choisir les valeurs considéées comme des tags par Influxdb
      	send_as_tags => ["user","device_address"]

      	# l'adresse du container Influxdb
        host => "{{logstash_influxDB_ip}}"

      	# Le nom de la base influx créée dans laquelle on souhaite inrer nos données
      	db => "logstash_data"

      	# Le nom du measurement de la base influxdb
      	measurement => "heart"

      	# Automatique quand on utilise un formart de donnée JSON en input

      	codec => json

      	# Option pour utiliser les "fields" comme donnée envoy� a influxdb
      	use_event_fields_for_data_points => true

      	# Ne rentrer dans influxdb que les champs qui nous intéressent
      	exclude_fields => ["time_bis", "message", "data", "@timestamp","@version", "type", "path", "host"]
        }
    }
}